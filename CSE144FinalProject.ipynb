{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# os.chdir('/content/CSE144')"
      ],
      "metadata": {
        "id": "v0YIty1m8vye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef48ae2-f8ea-479d-d1fe-fb2c1f7b8e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSE144'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 122 (delta 35), reused 14 (delta 14), pack-reused 71\u001b[K\n",
            "Receiving objects: 100% (122/122), 1.69 MiB | 4.68 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgb8FvwAGfeC",
        "outputId": "4ed14f59-753b-490a-b78b-c15733170254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5043 entries, 0 to 5042\n",
            "Data columns (total 18 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   color                   5024 non-null   object \n",
            " 1   director_name           4939 non-null   object \n",
            " 2   num_critic_for_reviews  4993 non-null   float64\n",
            " 3   duration                5028 non-null   float64\n",
            " 4   actor_2_name            5030 non-null   object \n",
            " 5   gross                   4159 non-null   float64\n",
            " 6   genres                  5043 non-null   object \n",
            " 7   actor_1_name            5036 non-null   object \n",
            " 8   movie_title             5043 non-null   object \n",
            " 9   actor_3_name            5020 non-null   object \n",
            " 10  num_user_for_reviews    5022 non-null   float64\n",
            " 11  language                5029 non-null   object \n",
            " 12  country                 5038 non-null   object \n",
            " 13  content_rating          4740 non-null   object \n",
            " 14  budget                  4551 non-null   float64\n",
            " 15  title_year              4935 non-null   float64\n",
            " 16  imdb_score              5043 non-null   float64\n",
            " 17  movie_facebook_likes    5043 non-null   int64  \n",
            "dtypes: float64(7), int64(1), object(10)\n",
            "memory usage: 709.3+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format=\"retina\"\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import random\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import math\n",
        "from IPython import display\n",
        "\n",
        "## column selection\n",
        "unique_data = pd.read_csv('/content/movie_metadata.csv').drop(['director_facebook_likes', 'actor_3_facebook_likes', 'actor_1_facebook_likes', 'cast_total_facebook_likes', 'actor_2_facebook_likes', 'num_voted_users', 'facenumber_in_poster', 'plot_keywords', 'movie_imdb_link', 'aspect_ratio'], axis=1)\n",
        "unique_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "UaEckSmRjmEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## getting rid of duplicate titles\n",
        "unique_data = unique_data.drop_duplicates(subset='movie_title', keep='first')\n",
        "unique_data = unique_data.drop('movie_title', axis=1)\n",
        "\n",
        "## missing values\n",
        "print(unique_data.isnull().sum())\n",
        "\n",
        "# remove rows that are missing budget or gross income values\n",
        "unique_data = unique_data.dropna(subset=['gross', 'budget'], how='any')\n",
        "\n",
        "## Remove rows with'TV'\n",
        "unique_data = unique_data[~unique_data['content_rating'].str.contains(\"TV\", na=False)]\n",
        "\n",
        "\n",
        "for column in unique_data.columns:\n",
        "    if unique_data[column].dtype == 'object':\n",
        "        unique_data.loc[:, column].fillna(\"Unknown\", inplace=True)\n",
        "    else:\n",
        "        # For numerical columns, fill missing values with the median value\n",
        "        unique_data.loc[:, column].fillna(unique_data[column].median(), inplace=True)\n",
        "\n",
        "# unique_data.dropna(how=\"any\",axis=0,inplace = True) #this just drops all missing values?\n",
        "print(unique_data.isnull().sum())\n",
        "\n",
        "## outliers for gross and budget\n",
        "Q1 = unique_data[['gross', 'budget']].quantile(0.25)\n",
        "Q3 = unique_data[['gross', 'budget']].quantile(0.75)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "unique_data = unique_data[(unique_data['gross'] >= lower_bound['gross']) & (unique_data['gross'] <= upper_bound['gross']) &\n",
        "                 (unique_data['budget'] >= lower_bound['budget']) & (unique_data['budget'] <= upper_bound['budget'])]\n",
        "\n",
        "## split genres up\n",
        "# unique_data['genres'] = unique_data['genres'].apply(lambda a: str(a).replace('|', ' '))\n",
        "unique_data['genres'] = unique_data['genres'].str.split('|')\n",
        "# one hot encode genres\n",
        "mlb = MultiLabelBinarizer()\n",
        "genres_encoded = mlb.fit_transform(unique_data['genres'])\n",
        "genres_df = pd.DataFrame(genres_encoded, columns=mlb.classes_, index=unique_data.index)\n",
        "\n",
        "unique_data = unique_data.drop('genres', axis=1).join(genres_df)\n",
        "\n",
        "\n",
        "\n",
        "unique_data.head()"
      ],
      "metadata": {
        "id": "ITs3_mSF5Keb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6ea0806-6ece-4454-aede-8c13983b3c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "color                      19\n",
            "director_name             102\n",
            "num_critic_for_reviews     49\n",
            "duration                   15\n",
            "actor_2_name               13\n",
            "gross                     863\n",
            "genres                      0\n",
            "actor_1_name                7\n",
            "actor_3_name               23\n",
            "num_user_for_reviews       21\n",
            "language                   14\n",
            "country                     5\n",
            "content_rating            300\n",
            "budget                    484\n",
            "title_year                106\n",
            "imdb_score                  0\n",
            "movie_facebook_likes        0\n",
            "dtype: int64\n",
            "color                     0\n",
            "director_name             0\n",
            "num_critic_for_reviews    0\n",
            "duration                  0\n",
            "actor_2_name              0\n",
            "gross                     0\n",
            "genres                    0\n",
            "actor_1_name              0\n",
            "actor_3_name              0\n",
            "num_user_for_reviews      0\n",
            "language                  0\n",
            "country                   0\n",
            "content_rating            0\n",
            "budget                    0\n",
            "title_year                0\n",
            "imdb_score                0\n",
            "movie_facebook_likes      0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c0f79faea027>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  unique_data['genres'] = unique_data['genres'].str.split('|')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     color  director_name  num_critic_for_reviews  duration  \\\n",
              "50   Color   Baz Luhrmann                   490.0     143.0   \n",
              "100  Color      Rob Cohen                   187.0     106.0   \n",
              "134  Color     Tim Burton                   526.0     113.0   \n",
              "157  Color   Dean Parisot                   135.0      90.0   \n",
              "192  Color  Phillip Noyce                   330.0     101.0   \n",
              "\n",
              "           actor_2_name        gross          actor_1_name      actor_3_name  \\\n",
              "50    Elizabeth Debicki  144812796.0     Leonardo DiCaprio      Steve Bisley   \n",
              "100          Vin Diesel  144512310.0           Paul Walker  Jordana Brewster   \n",
              "134  Chloë Grace Moretz   79711678.0           Johnny Depp   Christopher Lee   \n",
              "157       Richard Burgi  110332737.0  John Michael Higgins      David Herman   \n",
              "192      Andre Braugher  118311368.0   Angelina Jolie Pitt      August Diehl   \n",
              "\n",
              "     num_user_for_reviews language  ... Music Musical  Mystery  Romance  \\\n",
              "50                  753.0  English  ...     0       0        0        1   \n",
              "100                 988.0  English  ...     0       0        0        0   \n",
              "134                 479.0  English  ...     0       0        0        0   \n",
              "157                 258.0  English  ...     0       0        0        0   \n",
              "192                 514.0  English  ...     0       0        1        0   \n",
              "\n",
              "     Sci-Fi  Short  Sport  Thriller  War  Western  \n",
              "50        0      0      0         0    0        0  \n",
              "100       0      0      0         1    0        0  \n",
              "134       0      0      0         0    0        0  \n",
              "157       0      0      0         0    0        0  \n",
              "192       0      0      0         1    0        0  \n",
              "\n",
              "[5 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54dc6288-3e9a-4591-bf94-6688b81443b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>color</th>\n",
              "      <th>director_name</th>\n",
              "      <th>num_critic_for_reviews</th>\n",
              "      <th>duration</th>\n",
              "      <th>actor_2_name</th>\n",
              "      <th>gross</th>\n",
              "      <th>actor_1_name</th>\n",
              "      <th>actor_3_name</th>\n",
              "      <th>num_user_for_reviews</th>\n",
              "      <th>language</th>\n",
              "      <th>...</th>\n",
              "      <th>Music</th>\n",
              "      <th>Musical</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>Romance</th>\n",
              "      <th>Sci-Fi</th>\n",
              "      <th>Short</th>\n",
              "      <th>Sport</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Color</td>\n",
              "      <td>Baz Luhrmann</td>\n",
              "      <td>490.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>Elizabeth Debicki</td>\n",
              "      <td>144812796.0</td>\n",
              "      <td>Leonardo DiCaprio</td>\n",
              "      <td>Steve Bisley</td>\n",
              "      <td>753.0</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>Color</td>\n",
              "      <td>Rob Cohen</td>\n",
              "      <td>187.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>Vin Diesel</td>\n",
              "      <td>144512310.0</td>\n",
              "      <td>Paul Walker</td>\n",
              "      <td>Jordana Brewster</td>\n",
              "      <td>988.0</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>Color</td>\n",
              "      <td>Tim Burton</td>\n",
              "      <td>526.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>Chloë Grace Moretz</td>\n",
              "      <td>79711678.0</td>\n",
              "      <td>Johnny Depp</td>\n",
              "      <td>Christopher Lee</td>\n",
              "      <td>479.0</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>Color</td>\n",
              "      <td>Dean Parisot</td>\n",
              "      <td>135.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>Richard Burgi</td>\n",
              "      <td>110332737.0</td>\n",
              "      <td>John Michael Higgins</td>\n",
              "      <td>David Herman</td>\n",
              "      <td>258.0</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>Color</td>\n",
              "      <td>Phillip Noyce</td>\n",
              "      <td>330.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>Andre Braugher</td>\n",
              "      <td>118311368.0</td>\n",
              "      <td>Angelina Jolie Pitt</td>\n",
              "      <td>August Diehl</td>\n",
              "      <td>514.0</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 39 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54dc6288-3e9a-4591-bf94-6688b81443b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54dc6288-3e9a-4591-bf94-6688b81443b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54dc6288-3e9a-4591-bf94-6688b81443b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7023329a-5231-4ab9-8025-778eeddd9bc7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7023329a-5231-4ab9-8025-778eeddd9bc7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7023329a-5231-4ab9-8025-778eeddd9bc7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "unique_data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## One hot encoding\n",
        "categorical_features = ['color', 'language', 'country', 'content_rating', 'genres']\n",
        "actor_columns = ['actor_1_name', 'actor_2_name', 'actor_3_name']\n",
        "director_feature = 'director_name'\n",
        "\n",
        "actor_counts = unique_data[actor_columns].stack().value_counts()\n",
        "director_counts = unique_data[director_feature].value_counts()\n",
        "\n",
        "star_threshold = 0.1  # top 10%\n",
        "\n",
        "num_stars = int(len(actor_counts) * star_threshold)\n",
        "stars = set(actor_counts.head(num_stars).index)\n",
        "\n",
        "def count_stars(row, stars, actor_columns):\n",
        "    return sum(row[actor] in stars for actor in actor_columns)\n",
        "\n",
        "unique_data['num_stars'] = unique_data[actor_columns].apply(count_stars, axis=1, stars=stars, actor_columns=actor_columns)\n",
        "unique_data.drop(columns=actor_columns, inplace=True)\n",
        "\n",
        "unique_data['director_star_power'] = unique_data['director_name'].map(director_counts)\n",
        "\n",
        "\n",
        "print(\"actors and director replaced with star numbers:\")\n",
        "print(unique_data.head)\n",
        "\n",
        "def calculate_director_avg_gross(director_name, data):\n",
        "    director_movies = data[data['director_name'] == director_name]\n",
        "    if not director_movies.empty:\n",
        "        return director_movies['gross'].mean()\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "unique_data['director_avg_gross'] = unique_data['director_name'].apply(lambda x: calculate_director_avg_gross(x, unique_data))\n",
        "unique_data.drop(columns=['director_name'], inplace=True)\n",
        "\n",
        "\n",
        "#print(unique_data.columns)\n",
        "\n",
        "# def convert_features_to_one_hot(unique_data, feature_name_list):\n",
        "#   for feature_name in feature_name_list:\n",
        "#     df = pd.get_dummies(unique_data, columns=[feature_name])\n",
        "\n",
        "#   return df\n",
        "\n",
        "# data_encoded = convert_features_to_one_hot(unique_data, categorical_features)\n",
        "\n",
        "# data_encoded.columns\n",
        "\n",
        "\n",
        "def convert_features_to_one_hot(unique_data, feature_name_list):\n",
        "    print(\"Initial columns:\", unique_data.columns)\n",
        "    for feature_name in feature_name_list:\n",
        "        if feature_name in unique_data.columns:\n",
        "            unique_data = pd.get_dummies(unique_data, columns=[feature_name])\n",
        "            print(f\"Columns after encoding {feature_name}:\", unique_data.columns)\n",
        "        else:\n",
        "            print(f\"Warning: {feature_name} is not in DataFrame columns\")\n",
        "    return unique_data\n",
        "\n",
        "data_encoded = convert_features_to_one_hot(unique_data, categorical_features)\n",
        "\n",
        "print(\"Final columns:\", data_encoded.columns)\n",
        "# print(data_encoded)"
      ],
      "metadata": {
        "id": "gjWfDz7c39bO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b5adf8-918b-499f-f705-cee8f10d5721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actors and director replaced with star numbers:\n",
            "<bound method NDFrame.head of       color     director_name  num_critic_for_reviews  duration        gross  \\\n",
            "50    Color      Baz Luhrmann                   490.0     143.0  144812796.0   \n",
            "100   Color         Rob Cohen                   187.0     106.0  144512310.0   \n",
            "134   Color        Tim Burton                   526.0     113.0   79711678.0   \n",
            "157   Color      Dean Parisot                   135.0      90.0  110332737.0   \n",
            "192   Color     Phillip Noyce                   330.0     101.0  118311368.0   \n",
            "...     ...               ...                     ...       ...          ...   \n",
            "5033  Color     Shane Carruth                   143.0      77.0     424760.0   \n",
            "5034  Color  Neill Dela Llana                    35.0      80.0      70071.0   \n",
            "5035  Color  Robert Rodriguez                    56.0      81.0    2040920.0   \n",
            "5037  Color      Edward Burns                    14.0      95.0       4584.0   \n",
            "5042  Color          Jon Gunn                    43.0      90.0      85222.0   \n",
            "\n",
            "      num_user_for_reviews language      country content_rating       budget  \\\n",
            "50                   753.0  English    Australia          PG-13  105000000.0   \n",
            "100                  988.0  English          USA          PG-13   38000000.0   \n",
            "134                  479.0  English          USA          PG-13  100000000.0   \n",
            "157                  258.0  English          USA          PG-13  100000000.0   \n",
            "192                  514.0  English          USA          PG-13  110000000.0   \n",
            "...                    ...      ...          ...            ...          ...   \n",
            "5033                 371.0  English          USA          PG-13       7000.0   \n",
            "5034                  35.0  English  Philippines      Not Rated       7000.0   \n",
            "5035                 130.0  Spanish          USA              R       7000.0   \n",
            "5037                  14.0  English          USA      Not Rated       9000.0   \n",
            "5042                  84.0  English          USA             PG       1100.0   \n",
            "\n",
            "      ...  Mystery  Romance  Sci-Fi  Short  Sport  Thriller  War  Western  \\\n",
            "50    ...        0        1       0      0      0         0    0        0   \n",
            "100   ...        0        0       0      0      0         1    0        0   \n",
            "134   ...        0        0       0      0      0         0    0        0   \n",
            "157   ...        0        0       0      0      0         0    0        0   \n",
            "192   ...        1        0       0      0      0         1    0        0   \n",
            "...   ...      ...      ...     ...    ...    ...       ...  ...      ...   \n",
            "5033  ...        0        0       1      0      0         1    0        0   \n",
            "5034  ...        0        0       0      0      0         1    0        0   \n",
            "5035  ...        0        1       0      0      0         1    0        0   \n",
            "5037  ...        0        0       0      0      0         0    0        0   \n",
            "5042  ...        0        0       0      0      0         0    0        0   \n",
            "\n",
            "      num_stars  director_star_power  \n",
            "50            1                    3  \n",
            "100           2                    7  \n",
            "134           3                    9  \n",
            "157           1                    4  \n",
            "192           1                    9  \n",
            "...         ...                  ...  \n",
            "5033          0                    1  \n",
            "5034          0                    1  \n",
            "5035          0                   13  \n",
            "5037          0                    3  \n",
            "5042          0                    3  \n",
            "\n",
            "[3388 rows x 38 columns]>\n",
            "Initial columns: Index(['color', 'num_critic_for_reviews', 'duration', 'gross',\n",
            "       'num_user_for_reviews', 'language', 'country', 'content_rating',\n",
            "       'budget', 'title_year', 'imdb_score', 'movie_facebook_likes', 'Action',\n",
            "       'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
            "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
            "       'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller',\n",
            "       'War', 'Western', 'num_stars', 'director_star_power',\n",
            "       'director_avg_gross'],\n",
            "      dtype='object')\n",
            "Columns after encoding color: Index(['num_critic_for_reviews', 'duration', 'gross', 'num_user_for_reviews',\n",
            "       'language', 'country', 'content_rating', 'budget', 'title_year',\n",
            "       'imdb_score', 'movie_facebook_likes', 'Action', 'Adventure',\n",
            "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
            "       'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
            "       'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller',\n",
            "       'War', 'Western', 'num_stars', 'director_star_power',\n",
            "       'director_avg_gross', 'color_ Black and White', 'color_Color',\n",
            "       'color_Unknown'],\n",
            "      dtype='object')\n",
            "Columns after encoding language: Index(['num_critic_for_reviews', 'duration', 'gross', 'num_user_for_reviews',\n",
            "       'country', 'content_rating', 'budget', 'title_year', 'imdb_score',\n",
            "       'movie_facebook_likes', 'Action', 'Adventure', 'Animation', 'Biography',\n",
            "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
            "       'Film-Noir', 'History', 'Horror', 'Music', 'Musical', 'Mystery',\n",
            "       'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western',\n",
            "       'num_stars', 'director_star_power', 'director_avg_gross',\n",
            "       'color_ Black and White', 'color_Color', 'color_Unknown',\n",
            "       'language_Aboriginal', 'language_Arabic', 'language_Aramaic',\n",
            "       'language_Bosnian', 'language_Cantonese', 'language_Czech',\n",
            "       'language_Danish', 'language_Dari', 'language_Dutch',\n",
            "       'language_Dzongkha', 'language_English', 'language_Filipino',\n",
            "       'language_French', 'language_German', 'language_Hebrew',\n",
            "       'language_Hindi', 'language_Icelandic', 'language_Indonesian',\n",
            "       'language_Italian', 'language_Japanese', 'language_Kazakh',\n",
            "       'language_Korean', 'language_Mandarin', 'language_Maya',\n",
            "       'language_Mongolian', 'language_Norwegian', 'language_Persian',\n",
            "       'language_Portuguese', 'language_Romanian', 'language_Russian',\n",
            "       'language_Spanish', 'language_Swedish', 'language_Telugu',\n",
            "       'language_Unknown', 'language_Vietnamese', 'language_Zulu'],\n",
            "      dtype='object')\n",
            "Columns after encoding country: Index(['num_critic_for_reviews', 'duration', 'gross', 'num_user_for_reviews',\n",
            "       'content_rating', 'budget', 'title_year', 'imdb_score',\n",
            "       'movie_facebook_likes', 'Action',\n",
            "       ...\n",
            "       'country_Russia', 'country_South Africa', 'country_South Korea',\n",
            "       'country_Spain', 'country_Sweden', 'country_Taiwan', 'country_Thailand',\n",
            "       'country_UK', 'country_USA', 'country_West Germany'],\n",
            "      dtype='object', length=121)\n",
            "Columns after encoding content_rating: Index(['num_critic_for_reviews', 'duration', 'gross', 'num_user_for_reviews',\n",
            "       'budget', 'title_year', 'imdb_score', 'movie_facebook_likes', 'Action',\n",
            "       'Adventure',\n",
            "       ...\n",
            "       'content_rating_M', 'content_rating_NC-17', 'content_rating_Not Rated',\n",
            "       'content_rating_PG', 'content_rating_PG-13', 'content_rating_Passed',\n",
            "       'content_rating_R', 'content_rating_Unknown', 'content_rating_Unrated',\n",
            "       'content_rating_X'],\n",
            "      dtype='object', length=133)\n",
            "Warning: genres is not in DataFrame columns\n",
            "Final columns: Index(['num_critic_for_reviews', 'duration', 'gross', 'num_user_for_reviews',\n",
            "       'budget', 'title_year', 'imdb_score', 'movie_facebook_likes', 'Action',\n",
            "       'Adventure',\n",
            "       ...\n",
            "       'content_rating_M', 'content_rating_NC-17', 'content_rating_Not Rated',\n",
            "       'content_rating_PG', 'content_rating_PG-13', 'content_rating_Passed',\n",
            "       'content_rating_R', 'content_rating_Unknown', 'content_rating_Unrated',\n",
            "       'content_rating_X'],\n",
            "      dtype='object', length=133)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train test splitting\n",
        "train_set, test_set = train_test_split(data_encoded, test_size=0.1, random_state=42)\n",
        "\n",
        "print(type(train_set))\n",
        "\n",
        "print(train_set.head())\n",
        "print(test_set.head())\n",
        "print(train_set.num_stars.head(10))\n",
        "print(train_set.director_star_power.head(10))"
      ],
      "metadata": {
        "id": "UCI0X-b45Tfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf0cf78-5837-4ec5-fe6e-b77e4482850c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "      num_critic_for_reviews  duration        gross  num_user_for_reviews  \\\n",
            "2462                    70.0      93.0    3500000.0                 100.0   \n",
            "2090                    53.0     114.0   50728000.0                 166.0   \n",
            "2031                   156.0     110.0   25167270.0                 263.0   \n",
            "938                    140.0     116.0  105807520.0                 357.0   \n",
            "370                    269.0     121.0   83077470.0                 440.0   \n",
            "\n",
            "          budget  title_year  imdb_score  movie_facebook_likes  Action  \\\n",
            "2462   2700000.0      1986.0         5.9                     0       1   \n",
            "2090  22000000.0      1995.0         5.8                     0       1   \n",
            "2031  24000000.0      2000.0         6.3                   455       0   \n",
            "938   50000000.0      2003.0         6.4                     0       0   \n",
            "370   75000000.0      2008.0         7.1                     0       0   \n",
            "\n",
            "      Adventure  ...  content_rating_M  content_rating_NC-17  \\\n",
            "2462          0  ...             False                 False   \n",
            "2090          0  ...             False                 False   \n",
            "2031          0  ...             False                 False   \n",
            "938           0  ...             False                 False   \n",
            "370           0  ...             False                 False   \n",
            "\n",
            "      content_rating_Not Rated  content_rating_PG  content_rating_PG-13  \\\n",
            "2462                     False              False                 False   \n",
            "2090                     False              False                  True   \n",
            "2031                     False              False                 False   \n",
            "938                      False              False                  True   \n",
            "370                      False              False                  True   \n",
            "\n",
            "      content_rating_Passed  content_rating_R  content_rating_Unknown  \\\n",
            "2462                  False              True                   False   \n",
            "2090                  False             False                   False   \n",
            "2031                  False              True                   False   \n",
            "938                   False             False                   False   \n",
            "370                   False             False                   False   \n",
            "\n",
            "      content_rating_Unrated  content_rating_X  \n",
            "2462                   False             False  \n",
            "2090                   False             False  \n",
            "2031                   False             False  \n",
            "938                    False             False  \n",
            "370                    False             False  \n",
            "\n",
            "[5 rows x 133 columns]\n",
            "      num_critic_for_reviews  duration       gross  num_user_for_reviews  \\\n",
            "5021                    51.0      85.0    192467.0                  71.0   \n",
            "4780                     8.0      91.0   2712293.0                  11.0   \n",
            "3394                    11.0      89.0   4692814.0                  34.0   \n",
            "1699                   222.0     150.0  12712093.0                 671.0   \n",
            "797                    123.0     140.0  13082288.0                 247.0   \n",
            "\n",
            "          budget  title_year  imdb_score  movie_facebook_likes  Action  \\\n",
            "5021     15000.0      2005.0         6.6                   297       0   \n",
            "4780    450000.0      1991.0         5.9                   123       0   \n",
            "3394   8000000.0      1999.0         5.1                    77       0   \n",
            "1699  30000000.0      2005.0         6.7                     0       0   \n",
            "797   60000000.0      2006.0         6.6                  2000       1   \n",
            "\n",
            "      Adventure  ...  content_rating_M  content_rating_NC-17  \\\n",
            "5021          0  ...             False                 False   \n",
            "4780          0  ...             False                 False   \n",
            "3394          0  ...             False                 False   \n",
            "1699          0  ...             False                 False   \n",
            "797           1  ...             False                 False   \n",
            "\n",
            "      content_rating_Not Rated  content_rating_PG  content_rating_PG-13  \\\n",
            "5021                     False              False                 False   \n",
            "4780                     False              False                 False   \n",
            "3394                     False              False                  True   \n",
            "1699                     False              False                  True   \n",
            "797                      False              False                  True   \n",
            "\n",
            "      content_rating_Passed  content_rating_R  content_rating_Unknown  \\\n",
            "5021                  False              True                   False   \n",
            "4780                  False              True                   False   \n",
            "3394                  False             False                   False   \n",
            "1699                  False             False                   False   \n",
            "797                   False             False                   False   \n",
            "\n",
            "      content_rating_Unrated  content_rating_X  \n",
            "5021                   False             False  \n",
            "4780                   False             False  \n",
            "3394                   False             False  \n",
            "1699                   False             False  \n",
            "797                    False             False  \n",
            "\n",
            "[5 rows x 133 columns]\n",
            "2462    2\n",
            "2090    0\n",
            "2031    1\n",
            "938     3\n",
            "370     3\n",
            "1437    1\n",
            "2487    0\n",
            "1323    1\n",
            "849     2\n",
            "1214    2\n",
            "Name: num_stars, dtype: int64\n",
            "2462     1\n",
            "2090     4\n",
            "2031     3\n",
            "938      8\n",
            "370      2\n",
            "1437    10\n",
            "2487     1\n",
            "1323     1\n",
            "849      5\n",
            "1214     2\n",
            "Name: director_star_power, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Models"
      ],
      "metadata": {
        "id": "-YfV5I_TkHE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#accuracy function\n",
        "def within_percentage_accuracy(outputs, targets, percentage=0.10):\n",
        "    with torch.no_grad():\n",
        "        #convert torch tensors\n",
        "        outputs = torch.tensor(outputs)\n",
        "        targets = torch.tensor(targets.values)\n",
        "\n",
        "        deviation = percentage * targets\n",
        "        lower_bounds = targets - deviation\n",
        "        upper_bounds = targets + deviation\n",
        "\n",
        "        correct = torch.logical_and(outputs >= lower_bounds, outputs <= upper_bounds)\n",
        "        accuracy = torch.mean(correct.float())\n",
        "    return accuracy.item() * 100\n",
        "\n",
        "\n",
        "print(data_encoded.columns)\n",
        "independent_vars = train_set[data_encoded.columns.drop('gross')]\n",
        "dependent_var = train_set['gross']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(independent_vars, dependent_var, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression().fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test)\n",
        "\n",
        "lasso_model = Lasso(alpha=0.1)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "y_pred_lasso = lasso_model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"Linear Regression - MSE: {mse}, MAE: {mae}, R-squared: {r2}, RMSE: {rmse}\")\n",
        "\n",
        "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
        "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "rmse_ridge = np.sqrt(mse_ridge)\n",
        "\n",
        "print(f\"Ridge Regression - MSE: {mse_ridge}, MAE: {mae_ridge}, R-squared: {r2_ridge}, RMSE: {rmse_ridge}\")\n",
        "\n",
        "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
        "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "rmse_lasso = np.sqrt(mse_lasso)\n",
        "\n",
        "print(f\"Lasso Regression - MSE: {mse_lasso}, MAE: {mae_lasso}, R-squared: {r2_lasso}, RMSE: {rmse_lasso}\")\n",
        "\n",
        "accuracy_linear = within_percentage_accuracy(y_pred, y_test, percentage=0.4)\n",
        "accuracy_ridge = within_percentage_accuracy(y_pred_ridge, y_test, percentage=0.4)\n",
        "accuracy_lasso = within_percentage_accuracy(y_pred_lasso, y_test, percentage=0.4)\n",
        "\n",
        "print(f\"Linear Regression - Accuracy within 10%: {accuracy_linear}%\")\n",
        "print(f\"Ridge Regression - Accuracy within 10%: {accuracy_ridge}%\")\n",
        "print(f\"Lasso Regression - Accuracy within 10%: {accuracy_lasso}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjK6T9EHb71E",
        "outputId": "9930d6df-2cc1-4961-d183-7818ba6264a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['num_critic_for_reviews', 'duration', 'gross', 'num_user_for_reviews',\n",
            "       'budget', 'title_year', 'imdb_score', 'movie_facebook_likes', 'Action',\n",
            "       'Adventure',\n",
            "       ...\n",
            "       'content_rating_M', 'content_rating_NC-17', 'content_rating_Not Rated',\n",
            "       'content_rating_PG', 'content_rating_PG-13', 'content_rating_Passed',\n",
            "       'content_rating_R', 'content_rating_Unknown', 'content_rating_Unrated',\n",
            "       'content_rating_X'],\n",
            "      dtype='object', length=133)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.63748e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - MSE: 438742494937056.94, MAE: 14802097.054077286, R-squared: 0.6433362805881839, RMSE: 20946180.91531382\n",
            "Ridge Regression - MSE: 435776108141328.56, MAE: 14767997.201848933, R-squared: 0.6457477236555584, RMSE: 20875251.091695365\n",
            "Lasso Regression - MSE: 440019992994330.6, MAE: 14830284.366125463, R-squared: 0.6422977734595001, RMSE: 20976653.52229308\n",
            "Linear Regression - Accuracy within 10%: 46.22950851917267%\n",
            "Ridge Regression - Accuracy within 10%: 46.06557488441467%\n",
            "Lasso Regression - Accuracy within 10%: 46.393442153930664%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+17, tolerance: 2.909e+14\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "train_set, val_set = train_test_split(\n",
        "    train_set, test_size=0.222, random_state=42)  #0.25 x 0.8 = 0.2\n",
        "\n",
        "train_features = train_set.drop(columns=['gross']).values.astype(int)\n",
        "train_targets = train_set['gross'].values\n",
        "\n",
        "val_features = val_set.drop(columns=['gross']).values.astype(int)\n",
        "val_targets = val_set['gross'].values\n",
        "\n",
        "test_features = test_set.drop(columns=['gross']).values.astype(int)\n",
        "test_targets = test_set['gross'].values\n",
        "\n",
        "print(type(train_features))\n",
        "print(train_features)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x09kfXKApx9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59613be0-df4e-4a56-fec3-8790eb0457a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[ 200  152 1103 ...    0    0    0]\n",
            " [  16   95  158 ...    0    0    0]\n",
            " [ 113  102  301 ...    0    0    0]\n",
            " ...\n",
            " [  26  124   74 ...    0    0    0]\n",
            " [  81  121   94 ...    0    0    0]\n",
            " [ 169  110  374 ...    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feed Forward Neural Network"
      ],
      "metadata": {
        "id": "7wV7Ng6fj7cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn.functional as F\n",
        "train_features = torch.tensor(train_features, dtype=torch.float32)\n",
        "train_targets = torch.tensor(train_targets, dtype=torch.float32)\n",
        "\n",
        "val_features = torch.tensor(val_features, dtype=torch.float32)\n",
        "val_targets = torch.tensor(val_targets, dtype=torch.float32)\n",
        "\n",
        "test_features = torch.tensor(test_features, dtype=torch.float32)\n",
        "test_targets = torch.tensor(test_targets, dtype=torch.float32)\n",
        "\n",
        "class MovieDataset(Dataset):\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = features\n",
        "        self.targets = torch.tensor(targets, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.targets[idx]\n",
        "\n",
        "train_dataset = MovieDataset(train_features, train_targets)\n",
        "val_dataset = MovieDataset(val_features, val_targets)\n",
        "test_dataset = MovieDataset(test_features, test_targets)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc0 = nn.Linear(train_features.shape[1], 512)\n",
        "        self.bn0 = nn.BatchNorm1d(512)\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.fc4 = nn.Linear(64, 32)\n",
        "        self.bn4 = nn.BatchNorm1d(32)\n",
        "        self.fc5 = nn.Linear(32, 1)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual = self.residual_fc(x)\n",
        "        x = F.relu(self.bn0(self.fc0(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout3(x)\n",
        "        x = F.relu(self.bn4(self.fc4(x)))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.0, weight_decay=1e-5)  #L2 regularization\n",
        "# lr = 0.001\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=10, min_lr=0.0001)\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "def within_percentage_accuracy_FF(outputs, targets, percentage=0.20):\n",
        "    with torch.no_grad():\n",
        "        deviation = percentage * targets\n",
        "        lower_bounds = targets - deviation\n",
        "        upper_bounds = targets + deviation\n",
        "\n",
        "        correct = torch.logical_and(outputs >= lower_bounds, outputs <= upper_bounds)\n",
        "        accuracy = torch.mean(correct.float())\n",
        "    return accuracy.item() * 100\n",
        "\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = 200\n",
        "best_val_loss = float('inf')\n",
        "patience, trials = 10, 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        # print(\"Predictions:\", outputs[:5])\n",
        "        # print(\"Actual:\", targets[:5])\n",
        "        loss = criterion(outputs, targets)\n",
        "        # print(\"loss\", loss)\n",
        "        # print(\"loss item\", loss.item())\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        total_accuracy += within_percentage_accuracy_FF(outputs, targets)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "    train_losses.append(epoch_loss)\n",
        "    # print(train_losses)\n",
        "    epoch_accuracy = total_accuracy / len(train_loader)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    total_val_accuracy = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # print(\"val loss\", loss)\n",
        "            # print(\"val loss item\", loss.item())\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            total_val_accuracy += within_percentage_accuracy_FF(outputs, targets)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        print(f'Validation MSE: {val_loss:.4f}')\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracy = total_val_accuracy / len(val_loader)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "    # # Early stopping check\n",
        "    # if val_loss < best_val_loss:\n",
        "    #     best_val_loss = val_loss\n",
        "    #     trials = 0\n",
        "    # else:\n",
        "    #     trials += 1\n",
        "    #     if trials >= patience:\n",
        "    #         print(\"Early stopping triggered.\")\n",
        "    #         break\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "total_test_accuracy = 0.0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        # print(\"test loss\", loss)\n",
        "        # print(\"test loss item\", loss.item())\n",
        "        test_loss += loss.item() * inputs.size(0)\n",
        "        total_test_accuracy += within_percentage_accuracy_FF(outputs, targets)\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'Final Test MSE: {test_loss:.4f}')\n",
        "    test_accuracy = total_test_accuracy / len(test_loader)\n",
        "    print(f'Final Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uYAQMOG9Jr_",
        "outputId": "fbc1ee93-074b-4eac-ee03-447936bf3e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1bc1725ac09e>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_features = torch.tensor(train_features, dtype=torch.float32)\n",
            "<ipython-input-11-1bc1725ac09e>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_targets = torch.tensor(train_targets, dtype=torch.float32)\n",
            "<ipython-input-11-1bc1725ac09e>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_features = torch.tensor(val_features, dtype=torch.float32)\n",
            "<ipython-input-11-1bc1725ac09e>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_targets = torch.tensor(val_targets, dtype=torch.float32)\n",
            "<ipython-input-11-1bc1725ac09e>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_features = torch.tensor(test_features, dtype=torch.float32)\n",
            "<ipython-input-11-1bc1725ac09e>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_targets = torch.tensor(test_targets, dtype=torch.float32)\n",
            "<ipython-input-11-1bc1725ac09e>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.targets = torch.tensor(targets, dtype=torch.float32).view(-1, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Loss: 2311873078992274.5000\n",
            "Validation MSE: 2356675346918341.0000\n",
            "Epoch 2/200, Loss: 2309488802000571.5000\n",
            "Validation MSE: 2351384883363453.0000\n",
            "Epoch 3/200, Loss: 2304334028922562.5000\n",
            "Validation MSE: 2345660812091065.5000\n",
            "Epoch 4/200, Loss: 2296266404090263.5000\n",
            "Validation MSE: 2334299732641196.0000\n",
            "Epoch 5/200, Loss: 2285596751770021.5000\n",
            "Validation MSE: 2320817477804044.0000\n",
            "Epoch 6/200, Loss: 2272275021424153.0000\n",
            "Validation MSE: 2305028352099199.5000\n",
            "Epoch 7/200, Loss: 2256498125171527.0000\n",
            "Validation MSE: 2280747013014036.5000\n",
            "Epoch 8/200, Loss: 2238060871040112.2500\n",
            "Validation MSE: 2262353322313809.5000\n",
            "Epoch 9/200, Loss: 2216180541528164.2500\n",
            "Validation MSE: 2233019678623777.2500\n",
            "Epoch 10/200, Loss: 2192837909190645.7500\n",
            "Validation MSE: 2216518498332097.2500\n",
            "Epoch 11/200, Loss: 2166528713336925.2500\n",
            "Validation MSE: 2177910115032325.7500\n",
            "Epoch 12/200, Loss: 2137736621243228.0000\n",
            "Validation MSE: 2153267317494722.0000\n",
            "Epoch 13/200, Loss: 2107210085734389.7500\n",
            "Validation MSE: 2112092969980236.7500\n",
            "Epoch 14/200, Loss: 2072940077010135.7500\n",
            "Validation MSE: 2082262982787943.2500\n",
            "Epoch 15/200, Loss: 2038831859495692.5000\n",
            "Validation MSE: 2040389138866478.5000\n",
            "Epoch 16/200, Loss: 2001440045553681.2500\n",
            "Validation MSE: 2007815927672305.7500\n",
            "Epoch 17/200, Loss: 1962425588621574.5000\n",
            "Validation MSE: 1962768165170746.2500\n",
            "Epoch 18/200, Loss: 1919410887738200.5000\n",
            "Validation MSE: 1932181285154289.7500\n",
            "Epoch 19/200, Loss: 1877001136031381.2500\n",
            "Validation MSE: 1850945338356976.5000\n",
            "Epoch 20/200, Loss: 1832146759375694.2500\n",
            "Validation MSE: 1823621698917725.5000\n",
            "Epoch 21/200, Loss: 1784067615303276.0000\n",
            "Validation MSE: 1757559272058111.5000\n",
            "Epoch 22/200, Loss: 1737548331785065.7500\n",
            "Validation MSE: 1738549600296560.7500\n",
            "Epoch 23/200, Loss: 1687530877980167.7500\n",
            "Validation MSE: 1644956311738346.7500\n",
            "Epoch 24/200, Loss: 1637545821120826.2500\n",
            "Validation MSE: 1598238699298368.2500\n",
            "Epoch 25/200, Loss: 1583458614425133.7500\n",
            "Validation MSE: 1539571912508795.7500\n",
            "Epoch 26/200, Loss: 1539105501600921.7500\n",
            "Validation MSE: 1489494609878907.0000\n",
            "Epoch 27/200, Loss: 1479938886552681.2500\n",
            "Validation MSE: 1457500389181618.5000\n",
            "Epoch 28/200, Loss: 1429949823758149.5000\n",
            "Validation MSE: 1423339803355980.0000\n",
            "Epoch 29/200, Loss: 1376208715694218.2500\n",
            "Validation MSE: 1317898501559113.0000\n",
            "Epoch 30/200, Loss: 1319973419220550.0000\n",
            "Validation MSE: 1315364121729777.2500\n",
            "Epoch 31/200, Loss: 1268178377677894.7500\n",
            "Validation MSE: 1266204967089731.2500\n",
            "Epoch 32/200, Loss: 1212811448628726.5000\n",
            "Validation MSE: 1179152260477514.7500\n",
            "Epoch 33/200, Loss: 1161981239258756.0000\n",
            "Validation MSE: 1112098852586125.3750\n",
            "Epoch 34/200, Loss: 1102453991134199.3750\n",
            "Validation MSE: 1070962081475646.0000\n",
            "Epoch 35/200, Loss: 1054731258051254.1250\n",
            "Validation MSE: 1004409074942436.0000\n",
            "Epoch 36/200, Loss: 1010775478364336.1250\n",
            "Validation MSE: 959137845276605.5000\n",
            "Epoch 37/200, Loss: 953339884405509.6250\n",
            "Validation MSE: 951543647028676.2500\n",
            "Epoch 38/200, Loss: 900332267058457.5000\n",
            "Validation MSE: 871623155297003.2500\n",
            "Epoch 39/200, Loss: 862126599478342.7500\n",
            "Validation MSE: 734410826476194.6250\n",
            "Epoch 40/200, Loss: 823325298518413.1250\n",
            "Validation MSE: 696477173637035.2500\n",
            "Epoch 41/200, Loss: 780218822642130.2500\n",
            "Validation MSE: 701054171534661.2500\n",
            "Epoch 42/200, Loss: 735404477215997.8750\n",
            "Validation MSE: 649206855467830.8750\n",
            "Epoch 43/200, Loss: 693765440426502.0000\n",
            "Validation MSE: 682884678860824.2500\n",
            "Epoch 44/200, Loss: 656636926188531.8750\n",
            "Validation MSE: 572315977640271.7500\n",
            "Epoch 45/200, Loss: 622317641847246.7500\n",
            "Validation MSE: 588219036551612.7500\n",
            "Epoch 46/200, Loss: 604320491776590.6250\n",
            "Validation MSE: 570438452234636.2500\n",
            "Epoch 47/200, Loss: 575227420558500.0000\n",
            "Validation MSE: 501624005155617.6250\n",
            "Epoch 48/200, Loss: 554319504087748.0000\n",
            "Validation MSE: 515802821997760.1250\n",
            "Epoch 49/200, Loss: 535906588689047.1250\n",
            "Validation MSE: 478119295641258.1875\n",
            "Epoch 50/200, Loss: 528740777580837.5625\n",
            "Validation MSE: 474824557910285.2500\n",
            "Epoch 51/200, Loss: 516642956515593.9375\n",
            "Validation MSE: 471069742525235.8125\n",
            "Epoch 52/200, Loss: 522191682164311.1875\n",
            "Validation MSE: 480442429207139.0625\n",
            "Epoch 53/200, Loss: 504871866894001.0000\n",
            "Validation MSE: 460904838082856.4375\n",
            "Epoch 54/200, Loss: 516715749319305.3125\n",
            "Validation MSE: 473310597996991.6875\n",
            "Epoch 55/200, Loss: 516702136744574.9375\n",
            "Validation MSE: 468975465351999.8750\n",
            "Epoch 56/200, Loss: 522096685549840.8125\n",
            "Validation MSE: 472955879177731.8125\n",
            "Epoch 57/200, Loss: 507427905628059.8750\n",
            "Validation MSE: 473973463967305.3750\n",
            "Epoch 58/200, Loss: 513209534343399.3750\n",
            "Validation MSE: 473449325648818.8750\n",
            "Epoch 59/200, Loss: 511182761378206.4375\n",
            "Validation MSE: 472754792770041.1875\n",
            "Epoch 60/200, Loss: 502081321779946.0000\n",
            "Validation MSE: 474961365277159.0625\n",
            "Epoch 61/200, Loss: 501288745725793.1250\n",
            "Validation MSE: 469904909637151.0000\n",
            "Epoch 62/200, Loss: 505814017798427.1875\n",
            "Validation MSE: 465488515096733.3125\n",
            "Epoch 63/200, Loss: 505179468237349.1250\n",
            "Validation MSE: 467728442493542.1250\n",
            "Epoch 64/200, Loss: 501830790301167.6250\n",
            "Validation MSE: 473721445450841.2500\n",
            "Epoch 65/200, Loss: 506455140633125.1250\n",
            "Validation MSE: 468627955333207.7500\n",
            "Epoch 66/200, Loss: 501626348352738.1875\n",
            "Validation MSE: 467096064863245.6250\n",
            "Epoch 67/200, Loss: 500691649870683.9375\n",
            "Validation MSE: 462246812053727.8750\n",
            "Epoch 68/200, Loss: 498782768789673.2500\n",
            "Validation MSE: 460723326498129.3125\n",
            "Epoch 69/200, Loss: 500691754777795.1250\n",
            "Validation MSE: 461957338018427.2500\n",
            "Epoch 70/200, Loss: 501218485461226.8750\n",
            "Validation MSE: 460646053317657.6875\n",
            "Epoch 71/200, Loss: 493042063580175.5625\n",
            "Validation MSE: 459296227411444.6250\n",
            "Epoch 72/200, Loss: 493557288658236.0000\n",
            "Validation MSE: 465168115225150.7500\n",
            "Epoch 73/200, Loss: 493685321619749.5625\n",
            "Validation MSE: 465274319413574.6875\n",
            "Epoch 74/200, Loss: 487598354702819.5000\n",
            "Validation MSE: 464750584689977.1250\n",
            "Epoch 75/200, Loss: 495994633709965.1875\n",
            "Validation MSE: 462813771031604.9375\n",
            "Epoch 76/200, Loss: 500568214601949.0625\n",
            "Validation MSE: 458514289202380.1875\n",
            "Epoch 77/200, Loss: 487281491657228.9375\n",
            "Validation MSE: 460485328331828.9375\n",
            "Epoch 78/200, Loss: 498242434075725.6875\n",
            "Validation MSE: 462125309373792.4375\n",
            "Epoch 79/200, Loss: 504953302085859.9375\n",
            "Validation MSE: 458947541054559.3125\n",
            "Epoch 80/200, Loss: 505779734165811.3750\n",
            "Validation MSE: 459217661468417.8750\n",
            "Epoch 81/200, Loss: 503620094533618.1875\n",
            "Validation MSE: 463562223900070.0000\n",
            "Epoch 82/200, Loss: 491752370977075.3750\n",
            "Validation MSE: 460385391139859.6875\n",
            "Epoch 83/200, Loss: 486152399788905.7500\n",
            "Validation MSE: 460731706531658.5000\n",
            "Epoch 84/200, Loss: 482418933037004.1875\n",
            "Validation MSE: 458679259939033.8125\n",
            "Epoch 85/200, Loss: 488946806718187.6875\n",
            "Validation MSE: 459561012769742.0625\n",
            "Epoch 86/200, Loss: 496726855978780.0625\n",
            "Validation MSE: 462898182384677.8125\n",
            "Epoch 87/200, Loss: 486155801857488.5000\n",
            "Validation MSE: 464016616927818.8750\n",
            "Epoch 88/200, Loss: 493647741278335.8125\n",
            "Validation MSE: 458007750406513.0625\n",
            "Epoch 89/200, Loss: 500578008704951.5000\n",
            "Validation MSE: 459041769879325.1250\n",
            "Epoch 90/200, Loss: 491711328870745.3750\n",
            "Validation MSE: 458384520435206.8125\n",
            "Epoch 91/200, Loss: 492211354753041.2500\n",
            "Validation MSE: 458702093903481.7500\n",
            "Epoch 92/200, Loss: 496747065932000.5000\n",
            "Validation MSE: 459732640219983.0000\n",
            "Epoch 93/200, Loss: 489088738117821.9375\n",
            "Validation MSE: 458903000296848.8125\n",
            "Epoch 94/200, Loss: 496339160998426.7500\n",
            "Validation MSE: 458583222247871.6875\n",
            "Epoch 95/200, Loss: 495379015016213.1250\n",
            "Validation MSE: 458499590477754.4375\n",
            "Epoch 96/200, Loss: 487070668425378.3125\n",
            "Validation MSE: 461475972728889.5000\n",
            "Epoch 97/200, Loss: 491007378615719.0625\n",
            "Validation MSE: 462295373940866.0625\n",
            "Epoch 98/200, Loss: 489167131569298.7500\n",
            "Validation MSE: 461015388487147.5625\n",
            "Epoch 99/200, Loss: 493084789123110.0000\n",
            "Validation MSE: 459559071569027.5625\n",
            "Epoch 100/200, Loss: 491453633209521.8750\n",
            "Validation MSE: 458871072288314.2500\n",
            "Epoch 101/200, Loss: 484772750922328.9375\n",
            "Validation MSE: 459546088630704.5625\n",
            "Epoch 102/200, Loss: 490481933299028.1875\n",
            "Validation MSE: 460958652849413.6875\n",
            "Epoch 103/200, Loss: 481514595431152.8750\n",
            "Validation MSE: 459898766230278.4375\n",
            "Epoch 104/200, Loss: 495590153195734.1250\n",
            "Validation MSE: 458937643091880.2500\n",
            "Epoch 105/200, Loss: 494279339803508.1250\n",
            "Validation MSE: 460446949991767.3750\n",
            "Epoch 106/200, Loss: 486955530664077.6250\n",
            "Validation MSE: 459875113775594.0625\n",
            "Epoch 107/200, Loss: 502552386226531.7500\n",
            "Validation MSE: 459973846973084.5625\n",
            "Epoch 108/200, Loss: 488881484274040.4375\n",
            "Validation MSE: 459934584074754.2500\n",
            "Epoch 109/200, Loss: 499030866298987.0625\n",
            "Validation MSE: 458940815200007.9375\n",
            "Epoch 110/200, Loss: 488600554347148.7500\n",
            "Validation MSE: 459472788750965.2500\n",
            "Epoch 111/200, Loss: 499021913885994.7500\n",
            "Validation MSE: 459534196880527.6875\n",
            "Epoch 112/200, Loss: 498318894214760.5000\n",
            "Validation MSE: 461397504673607.4375\n",
            "Epoch 113/200, Loss: 500271548268875.5625\n",
            "Validation MSE: 461420431718148.9375\n",
            "Epoch 114/200, Loss: 487321352059076.8750\n",
            "Validation MSE: 459551653759638.5000\n",
            "Epoch 115/200, Loss: 497424395130510.4375\n",
            "Validation MSE: 462047493126981.9375\n",
            "Epoch 116/200, Loss: 495392204737199.2500\n",
            "Validation MSE: 459492221376490.8125\n",
            "Epoch 117/200, Loss: 484786546603538.1250\n",
            "Validation MSE: 460257979559143.4375\n",
            "Epoch 118/200, Loss: 485846184928268.0625\n",
            "Validation MSE: 457645623640983.6250\n",
            "Epoch 119/200, Loss: 483195404038896.8750\n",
            "Validation MSE: 460948652141775.2500\n",
            "Epoch 120/200, Loss: 491058610461794.4375\n",
            "Validation MSE: 457496534162475.8750\n",
            "Epoch 121/200, Loss: 488963734617918.6250\n",
            "Validation MSE: 459598797587908.2500\n",
            "Epoch 122/200, Loss: 493798262725730.4375\n",
            "Validation MSE: 460022961442737.3750\n",
            "Epoch 123/200, Loss: 505512545259789.3750\n",
            "Validation MSE: 459826910578890.6875\n",
            "Epoch 124/200, Loss: 492354490773759.5625\n",
            "Validation MSE: 461077200211598.9375\n",
            "Epoch 125/200, Loss: 483497635315104.1875\n",
            "Validation MSE: 458108762480264.8750\n",
            "Epoch 126/200, Loss: 488936884565135.3125\n",
            "Validation MSE: 458041672846869.9375\n",
            "Epoch 127/200, Loss: 492912541152703.2500\n",
            "Validation MSE: 461013029219027.0000\n",
            "Epoch 128/200, Loss: 496303554710080.7500\n",
            "Validation MSE: 461132609086274.9375\n",
            "Epoch 129/200, Loss: 500426432641193.2500\n",
            "Validation MSE: 459843745982340.0000\n",
            "Epoch 130/200, Loss: 503980896061105.0000\n",
            "Validation MSE: 458824415817104.8125\n",
            "Epoch 131/200, Loss: 503285752910839.3750\n",
            "Validation MSE: 460255976057216.1875\n",
            "Epoch 132/200, Loss: 489249417787561.2500\n",
            "Validation MSE: 461028783247886.3750\n",
            "Epoch 133/200, Loss: 492409389502484.7500\n",
            "Validation MSE: 458543289450423.3750\n",
            "Epoch 134/200, Loss: 494426860137977.9375\n",
            "Validation MSE: 458603631669181.4375\n",
            "Epoch 135/200, Loss: 495257510174126.0000\n",
            "Validation MSE: 458995988995406.2500\n",
            "Epoch 136/200, Loss: 487811162738736.3750\n",
            "Validation MSE: 458332606475180.8125\n",
            "Epoch 137/200, Loss: 493840588671027.8125\n",
            "Validation MSE: 459101850006744.3125\n",
            "Epoch 138/200, Loss: 489813620849748.6250\n",
            "Validation MSE: 459164688090394.8750\n",
            "Epoch 139/200, Loss: 495159082689713.8750\n",
            "Validation MSE: 460774319520339.9375\n",
            "Epoch 140/200, Loss: 482208032454548.9375\n",
            "Validation MSE: 459078124545149.5625\n",
            "Epoch 141/200, Loss: 488882418762142.4375\n",
            "Validation MSE: 459980053303919.1875\n",
            "Epoch 142/200, Loss: 491718465723020.7500\n",
            "Validation MSE: 460032112633441.5625\n",
            "Epoch 143/200, Loss: 486398765199201.1250\n",
            "Validation MSE: 459775856841496.5625\n",
            "Epoch 144/200, Loss: 487649338823256.9375\n",
            "Validation MSE: 457279694568503.9375\n",
            "Epoch 145/200, Loss: 496192112745957.2500\n",
            "Validation MSE: 460158195270309.6250\n",
            "Epoch 146/200, Loss: 496789764088181.0000\n",
            "Validation MSE: 458522550481966.8750\n",
            "Epoch 147/200, Loss: 486873311781015.9375\n",
            "Validation MSE: 462799183378592.3125\n",
            "Epoch 148/200, Loss: 503772662971117.4375\n",
            "Validation MSE: 458608129598662.1250\n",
            "Epoch 149/200, Loss: 485919647292846.0000\n",
            "Validation MSE: 460560617340105.1875\n",
            "Epoch 150/200, Loss: 485763112585682.2500\n",
            "Validation MSE: 460144026428154.3125\n",
            "Epoch 151/200, Loss: 486999391512448.1875\n",
            "Validation MSE: 457422136353965.9375\n",
            "Epoch 152/200, Loss: 482473226541100.8750\n",
            "Validation MSE: 458836608318084.3750\n",
            "Epoch 153/200, Loss: 489868962293273.0625\n",
            "Validation MSE: 460330104736382.3125\n",
            "Epoch 154/200, Loss: 488169730887756.0000\n",
            "Validation MSE: 461413095688394.6875\n",
            "Epoch 155/200, Loss: 495699920154299.3750\n",
            "Validation MSE: 461229647413223.8125\n",
            "Epoch 156/200, Loss: 482142856167396.3750\n",
            "Validation MSE: 461357876046837.4375\n",
            "Epoch 157/200, Loss: 494776227129851.6875\n",
            "Validation MSE: 457345052456176.5000\n",
            "Epoch 158/200, Loss: 489141928060220.0000\n",
            "Validation MSE: 459961074134078.0000\n",
            "Epoch 159/200, Loss: 482111522042912.8125\n",
            "Validation MSE: 459849004462424.8750\n",
            "Epoch 160/200, Loss: 487445428822913.9375\n",
            "Validation MSE: 459599273545383.1250\n",
            "Epoch 161/200, Loss: 492191375833119.0625\n",
            "Validation MSE: 460890120722386.6250\n",
            "Epoch 162/200, Loss: 494586246688940.6875\n",
            "Validation MSE: 459053072518750.5625\n",
            "Epoch 163/200, Loss: 496071155921869.9375\n",
            "Validation MSE: 458987159124321.9375\n",
            "Epoch 164/200, Loss: 500673821942630.3125\n",
            "Validation MSE: 460840612273147.4375\n",
            "Epoch 165/200, Loss: 492435635066234.1875\n",
            "Validation MSE: 461630893442306.6250\n",
            "Epoch 166/200, Loss: 492254095743462.9375\n",
            "Validation MSE: 456766738400780.8750\n",
            "Epoch 167/200, Loss: 484715390497880.0625\n",
            "Validation MSE: 458449796097173.7500\n",
            "Epoch 168/200, Loss: 489776755449731.6875\n",
            "Validation MSE: 462028356295917.5000\n",
            "Epoch 169/200, Loss: 488420562149638.5000\n",
            "Validation MSE: 459558038964838.1250\n",
            "Epoch 170/200, Loss: 497550955657910.1875\n",
            "Validation MSE: 458572945372884.5000\n",
            "Epoch 171/200, Loss: 484905551781901.8125\n",
            "Validation MSE: 461407979604001.2500\n",
            "Epoch 172/200, Loss: 489037591487555.3750\n",
            "Validation MSE: 459363656355979.1250\n",
            "Epoch 173/200, Loss: 490601193106302.5000\n",
            "Validation MSE: 459724254090153.8125\n",
            "Epoch 174/200, Loss: 489063728409636.2500\n",
            "Validation MSE: 459127629376259.3750\n",
            "Epoch 175/200, Loss: 497152926195421.8750\n",
            "Validation MSE: 460881115793320.2500\n",
            "Epoch 176/200, Loss: 501013065568028.0625\n",
            "Validation MSE: 457299230632876.8125\n",
            "Epoch 177/200, Loss: 490291839463375.6250\n",
            "Validation MSE: 459589060805455.0000\n",
            "Epoch 178/200, Loss: 501882697706034.9375\n",
            "Validation MSE: 458641509270060.6250\n",
            "Epoch 179/200, Loss: 491934926269200.0000\n",
            "Validation MSE: 460637966550855.4375\n",
            "Epoch 180/200, Loss: 479649973834218.4375\n",
            "Validation MSE: 459249370505784.7500\n",
            "Epoch 181/200, Loss: 488652436572046.0000\n",
            "Validation MSE: 460007782696436.6250\n",
            "Epoch 182/200, Loss: 493865854224684.4375\n",
            "Validation MSE: 459681275868666.6875\n",
            "Epoch 183/200, Loss: 491730891840196.0000\n",
            "Validation MSE: 459529649585885.5625\n",
            "Epoch 184/200, Loss: 503630692245462.5625\n",
            "Validation MSE: 458344143053925.3125\n",
            "Epoch 185/200, Loss: 494277200411401.0625\n",
            "Validation MSE: 460141271049220.5625\n",
            "Epoch 186/200, Loss: 497004891510552.6250\n",
            "Validation MSE: 458844163715513.6875\n",
            "Epoch 187/200, Loss: 503264975248316.6250\n",
            "Validation MSE: 459234673069807.7500\n",
            "Epoch 188/200, Loss: 496666442666861.2500\n",
            "Validation MSE: 458578486959196.2500\n",
            "Epoch 189/200, Loss: 490838997722870.0625\n",
            "Validation MSE: 460379578441667.5000\n",
            "Epoch 190/200, Loss: 490039326915088.3750\n",
            "Validation MSE: 459074183163256.6250\n",
            "Epoch 191/200, Loss: 482442266325026.5625\n",
            "Validation MSE: 459576619446568.4375\n",
            "Epoch 192/200, Loss: 488347129265430.0000\n",
            "Validation MSE: 460426936879524.5000\n",
            "Epoch 193/200, Loss: 498874648350188.1250\n",
            "Validation MSE: 459378855918914.1875\n",
            "Epoch 194/200, Loss: 505862459081394.7500\n",
            "Validation MSE: 459760573813770.5625\n",
            "Epoch 195/200, Loss: 499415207590250.6250\n",
            "Validation MSE: 459640585890926.4375\n",
            "Epoch 196/200, Loss: 492835835494814.4375\n",
            "Validation MSE: 459672920815098.6875\n",
            "Epoch 197/200, Loss: 482176882964317.6875\n",
            "Validation MSE: 460668393333111.1250\n",
            "Epoch 198/200, Loss: 485873902586626.1875\n",
            "Validation MSE: 459885763912660.1250\n",
            "Epoch 199/200, Loss: 488403518082540.1250\n",
            "Validation MSE: 459552869748463.7500\n",
            "Epoch 200/200, Loss: 485075331209896.3750\n",
            "Validation MSE: 458314487627098.3750\n",
            "Final Test MSE: 460020720986456.3750\n",
            "Final Test Accuracy: 27.8677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "print(train_losses)\n",
        "\n",
        "plt.title('Train Loss Progression')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "print(val_losses)\n",
        "\n",
        "plt.scatter(len(train_losses), test_loss, color='red', label='Test Loss', zorder=5)\n",
        "\n",
        "plt.title('Val Loss Progression')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# losses without the super high val loss at the start, which I dont know the cause of\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.ylim(top=train_losses[0])\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.scatter(len(train_losses), test_loss, color='red', label='Test Loss', zorder=5)\n",
        "\n",
        "plt.title('Combined Loss Progression')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracies, label='Training Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "\n",
        "plt.scatter(len(train_accuracies), test_accuracy, color='red', label='Test Accuracy', zorder=5)\n",
        "\n",
        "plt.title('Accuracy Progression')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "n6jdIlKnCwS-",
        "outputId": "e2a51a5e-4fab-4582-9789-db4ec7dfef7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-302ae94acaa2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train Loss Progression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model using Keras"
      ],
      "metadata": {
        "id": "anF_m4U9jXhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Embedding, Dense, Input, Concatenate, Flatten, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
        "\n",
        "unique_data = pd.read_csv('/content/movie_metadata.csv')\n",
        "\n",
        "unique_data = unique_data.drop(['director_facebook_likes', 'actor_3_facebook_likes', 'actor_1_facebook_likes',\n",
        "                                'cast_total_facebook_likes', 'actor_2_facebook_likes', 'num_voted_users',\n",
        "                                'facenumber_in_poster', 'plot_keywords', 'movie_imdb_link', 'aspect_ratio'], axis=1)\n",
        "\n",
        "#duplicate titles\n",
        "unique_data = unique_data.drop_duplicates(subset='movie_title', keep='first')\n",
        "unique_data = unique_data.drop('movie_title', axis=1)\n",
        "\n",
        "unique_data = unique_data.dropna(subset=['gross', 'budget'], how='any')\n",
        "unique_data = unique_data[~unique_data['content_rating'].str.contains(\"TV\", na=False)]\n",
        "\n",
        "for column in unique_data.columns:\n",
        "    if unique_data[column].dtype == 'object':\n",
        "        unique_data[column].fillna(\"Unknown\", inplace=True)\n",
        "    else:\n",
        "        unique_data[column].fillna(unique_data[column].median(), inplace=True)\n",
        "\n",
        "# Outliers for gross and budget\n",
        "Q1 = unique_data[['gross', 'budget']].quantile(0.25)\n",
        "Q3 = unique_data[['gross', 'budget']].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "unique_data = unique_data[(unique_data['gross'] >= lower_bound['gross']) & (unique_data['gross'] <= upper_bound['gross']) &\n",
        "                          (unique_data['budget'] >= lower_bound['budget']) & (unique_data['budget'] <= upper_bound['budget'])]\n",
        "\n",
        "unique_data['genres'] = unique_data['genres'].str.split('|')\n",
        "mlb = MultiLabelBinarizer()\n",
        "genres_encoded = mlb.fit_transform(unique_data['genres'])\n",
        "genres_df = pd.DataFrame(genres_encoded, columns=mlb.classes_, index=unique_data.index)\n",
        "\n",
        "unique_data = unique_data.drop('genres', axis=1).join(genres_df)\n",
        "\n",
        "categorical_features = ['color', 'language', 'country', 'content_rating']\n",
        "target_column = 'gross'\n",
        "\n",
        "numeric_features = unique_data.select_dtypes(include=[float, int]).columns.tolist()\n",
        "numeric_features = [feature for feature in numeric_features if feature not in categorical_features + [target_column]]\n",
        "\n",
        "for feature in categorical_features:\n",
        "    unique_data[feature] = unique_data[feature].astype('category').cat.codes\n",
        "\n",
        "scaler = StandardScaler()\n",
        "unique_data[numeric_features] = scaler.fit_transform(unique_data[numeric_features])\n",
        "\n",
        "X = unique_data.drop(columns=[target_column])\n",
        "y = unique_data[target_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "input_layers = []\n",
        "embedding_layers = []\n",
        "\n",
        "for feature in categorical_features:\n",
        "    vocab_size = unique_data[feature].nunique()\n",
        "    embedding_dim = 8\n",
        "    input_layer = Input(shape=(1,), name=f\"input_{feature}\")\n",
        "    input_layers.append(input_layer)\n",
        "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name=f\"embedding_{feature}\")(input_layer)\n",
        "    embedding_layer = Flatten()(embedding_layer)\n",
        "    embedding_layers.append(embedding_layer)\n",
        "\n",
        "numeric_input = Input(shape=(len(numeric_features),), name='numeric_input')\n",
        "input_layers.append(numeric_input)\n",
        "embedding_layers.append(numeric_input)\n",
        "\n",
        "concatenated = Concatenate()(embedding_layers)\n",
        "\n",
        "x = Dense(256, activation='relu')(concatenated)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "output = Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layers, outputs=output)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "train_inputs = {f\"input_{feature}\": X_train[feature] for feature in categorical_features}\n",
        "train_inputs['numeric_input'] = X_train[numeric_features]\n",
        "\n",
        "test_inputs = {f\"input_{feature}\": X_test[feature] for feature in categorical_features}\n",
        "test_inputs['numeric_input'] = X_test[numeric_features]\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_inputs, y_train, epochs=200, batch_size=32, validation_data=(test_inputs, y_test), callbacks=[early_stopping])\n",
        "\n",
        "loss, mae = model.evaluate(test_inputs, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "print(f'Test MAE: {mae}')\n",
        "\n",
        "def custom_accuracy(y_true, y_pred, threshold=0.1):\n",
        "    diff = tf.abs(y_true - y_pred)\n",
        "    return tf.reduce_mean(tf.cast(diff <= threshold * y_true, tf.float32))\n",
        "\n",
        "y_pred = model.predict(test_inputs).flatten()\n",
        "custom_acc = custom_accuracy(y_test.values, y_pred)\n",
        "print(f'Custom Accuracy: {custom_acc.numpy()}')\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R^2: {r2}')\n"
      ],
      "metadata": {
        "id": "YqGjuGxbuoGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc756be1-8c4c-4297-d1b7-93fe595c1379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_color (InputLayer)    [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_language (InputLayer  [(None, 1)]                  0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " input_country (InputLayer)  [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_content_rating (Inpu  [(None, 1)]                  0         []                            \n",
            " tLayer)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_color (Embedding  (None, 1, 8)                 24        ['input_color[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding_language (Embedd  (None, 1, 8)                 288       ['input_language[0][0]']      \n",
            " ing)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_country (Embeddi  (None, 1, 8)                 376       ['input_country[0][0]']       \n",
            " ng)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_content_rating (  (None, 1, 8)                 104       ['input_content_rating[0][0]']\n",
            " Embedding)                                                                                       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 8)                    0         ['embedding_color[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 8)                    0         ['embedding_language[0][0]']  \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 8)                    0         ['embedding_country[0][0]']   \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 8)                    0         ['embedding_content_rating[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " numeric_input (InputLayer)  [(None, 30)]                 0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 62)                   0         ['flatten[0][0]',             \n",
            "                                                                     'flatten_1[0][0]',           \n",
            "                                                                     'flatten_2[0][0]',           \n",
            "                                                                     'flatten_3[0][0]',           \n",
            "                                                                     'numeric_input[0][0]']       \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  16128     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 256)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 128)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64)                   8256      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 64)                   0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    65        ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 58137 (227.10 KB)\n",
            "Trainable params: 58137 (227.10 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "85/85 [==============================] - 2s 7ms/step - loss: 2306295700914176.0000 - mae: 33272128.0000 - val_loss: 2464022469279744.0000 - val_mae: 34815280.0000\n",
            "Epoch 2/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2304953523634176.0000 - mae: 33254628.0000 - val_loss: 2458537259171840.0000 - val_mae: 34747744.0000\n",
            "Epoch 3/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2280031975899136.0000 - mae: 32950226.0000 - val_loss: 2392824796413952.0000 - val_mae: 33986148.0000\n",
            "Epoch 4/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 2127320655593472.0000 - mae: 31332424.0000 - val_loss: 2100159416631296.0000 - val_mae: 30963258.0000\n",
            "Epoch 5/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1698119607648256.0000 - mae: 27448746.0000 - val_loss: 1518288119005184.0000 - val_mae: 26112556.0000\n",
            "Epoch 6/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1232170551083008.0000 - mae: 24906344.0000 - val_loss: 1148045697744896.0000 - val_mae: 25025472.0000\n",
            "Epoch 7/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1089227462803456.0000 - mae: 25478552.0000 - val_loss: 1087581685022720.0000 - val_mae: 25262410.0000\n",
            "Epoch 8/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1059710098735104.0000 - mae: 25344652.0000 - val_loss: 1062502632783872.0000 - val_mae: 25118496.0000\n",
            "Epoch 9/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 1033998880997376.0000 - mae: 24992980.0000 - val_loss: 1042513385226240.0000 - val_mae: 24934094.0000\n",
            "Epoch 10/200\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 1005486874820608.0000 - mae: 24783470.0000 - val_loss: 1025843744735232.0000 - val_mae: 24668326.0000\n",
            "Epoch 11/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 980191060951040.0000 - mae: 24342456.0000 - val_loss: 1009676212764672.0000 - val_mae: 24444804.0000\n",
            "Epoch 12/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 976964265443328.0000 - mae: 24203946.0000 - val_loss: 993581561020416.0000 - val_mae: 24249088.0000\n",
            "Epoch 13/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 974770745114624.0000 - mae: 24152862.0000 - val_loss: 978986591059968.0000 - val_mae: 23984482.0000\n",
            "Epoch 14/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 934929756061696.0000 - mae: 23521512.0000 - val_loss: 963956755660800.0000 - val_mae: 23799910.0000\n",
            "Epoch 15/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 929629766418432.0000 - mae: 23543632.0000 - val_loss: 949605189550080.0000 - val_mae: 23602954.0000\n",
            "Epoch 16/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 926815086444544.0000 - mae: 23298064.0000 - val_loss: 936456818262016.0000 - val_mae: 23337080.0000\n",
            "Epoch 17/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 904395961139200.0000 - mae: 23028530.0000 - val_loss: 922266648969216.0000 - val_mae: 23175016.0000\n",
            "Epoch 18/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 887505264050176.0000 - mae: 22856388.0000 - val_loss: 911927521837056.0000 - val_mae: 22855080.0000\n",
            "Epoch 19/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 880695660511232.0000 - mae: 22682296.0000 - val_loss: 899021346439168.0000 - val_mae: 22668494.0000\n",
            "Epoch 20/200\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 867702042263552.0000 - mae: 22258314.0000 - val_loss: 885652455424000.0000 - val_mae: 22532540.0000\n",
            "Epoch 21/200\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 857772144984064.0000 - mae: 22055800.0000 - val_loss: 876237484457984.0000 - val_mae: 22270500.0000\n",
            "Epoch 22/200\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 838754633777152.0000 - mae: 21948228.0000 - val_loss: 865835274993664.0000 - val_mae: 22094208.0000\n",
            "Epoch 23/200\n",
            "85/85 [==============================] - 1s 14ms/step - loss: 834697567404032.0000 - mae: 21695910.0000 - val_loss: 856613711773696.0000 - val_mae: 21890238.0000\n",
            "Epoch 24/200\n",
            "85/85 [==============================] - 1s 10ms/step - loss: 824683448500224.0000 - mae: 21453012.0000 - val_loss: 847127739629568.0000 - val_mae: 21726446.0000\n",
            "Epoch 25/200\n",
            "85/85 [==============================] - 1s 10ms/step - loss: 820459146838016.0000 - mae: 21398252.0000 - val_loss: 839712478593024.0000 - val_mae: 21497684.0000\n",
            "Epoch 26/200\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 813895967047680.0000 - mae: 21077448.0000 - val_loss: 832474250739712.0000 - val_mae: 21330186.0000\n",
            "Epoch 27/200\n",
            "85/85 [==============================] - 1s 10ms/step - loss: 787072285671424.0000 - mae: 20764330.0000 - val_loss: 822805071396864.0000 - val_mae: 21266424.0000\n",
            "Epoch 28/200\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 778778636713984.0000 - mae: 20519916.0000 - val_loss: 817473809022976.0000 - val_mae: 21082778.0000\n",
            "Epoch 29/200\n",
            "85/85 [==============================] - 1s 13ms/step - loss: 777405992009728.0000 - mae: 20530782.0000 - val_loss: 811751436189696.0000 - val_mae: 20918268.0000\n",
            "Epoch 30/200\n",
            "85/85 [==============================] - 1s 13ms/step - loss: 763698201231360.0000 - mae: 20166938.0000 - val_loss: 805587554140160.0000 - val_mae: 20827900.0000\n",
            "Epoch 31/200\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 763047580794880.0000 - mae: 20169912.0000 - val_loss: 800035839148032.0000 - val_mae: 20781526.0000\n",
            "Epoch 32/200\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 757801009807360.0000 - mae: 20068992.0000 - val_loss: 794408291139584.0000 - val_mae: 20740538.0000\n",
            "Epoch 33/200\n",
            "85/85 [==============================] - 1s 8ms/step - loss: 755684798889984.0000 - mae: 20044850.0000 - val_loss: 792103705640960.0000 - val_mae: 20502278.0000\n",
            "Epoch 34/200\n",
            "85/85 [==============================] - 1s 9ms/step - loss: 741044664664064.0000 - mae: 19806726.0000 - val_loss: 788022144532480.0000 - val_mae: 20446582.0000\n",
            "Epoch 35/200\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 747220223655936.0000 - mae: 19766166.0000 - val_loss: 785078749757440.0000 - val_mae: 20307836.0000\n",
            "Epoch 36/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 717579647713280.0000 - mae: 19446354.0000 - val_loss: 779570118656000.0000 - val_mae: 20352502.0000\n",
            "Epoch 37/200\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 719741828202496.0000 - mae: 19462698.0000 - val_loss: 778126472773632.0000 - val_mae: 20204556.0000\n",
            "Epoch 38/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 744019466387456.0000 - mae: 19587238.0000 - val_loss: 773866938957824.0000 - val_mae: 20178028.0000\n",
            "Epoch 39/200\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 735503351545856.0000 - mae: 19491810.0000 - val_loss: 772536505729024.0000 - val_mae: 20050862.0000\n",
            "Epoch 40/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 721373177577472.0000 - mae: 19307726.0000 - val_loss: 768510779195392.0000 - val_mae: 20012978.0000\n",
            "Epoch 41/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 717585083531264.0000 - mae: 19143562.0000 - val_loss: 765136612622336.0000 - val_mae: 20024916.0000\n",
            "Epoch 42/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 728472825626624.0000 - mae: 19394382.0000 - val_loss: 764342446325760.0000 - val_mae: 19905088.0000\n",
            "Epoch 43/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 728816758554624.0000 - mae: 19353456.0000 - val_loss: 763161330319360.0000 - val_mae: 19835920.0000\n",
            "Epoch 44/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 720852815446016.0000 - mae: 19220268.0000 - val_loss: 760771315236864.0000 - val_mae: 19788784.0000\n",
            "Epoch 45/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 718263352819712.0000 - mae: 18992098.0000 - val_loss: 757565390585856.0000 - val_mae: 19864746.0000\n",
            "Epoch 46/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 713425676140544.0000 - mae: 19099880.0000 - val_loss: 756894637490176.0000 - val_mae: 19764930.0000\n",
            "Epoch 47/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 706173825187840.0000 - mae: 18795076.0000 - val_loss: 754828556894208.0000 - val_mae: 19752884.0000\n",
            "Epoch 48/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 710630524846080.0000 - mae: 18951874.0000 - val_loss: 753095537590272.0000 - val_mae: 19722508.0000\n",
            "Epoch 49/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 702101726429184.0000 - mae: 18881400.0000 - val_loss: 750693040259072.0000 - val_mae: 19724754.0000\n",
            "Epoch 50/200\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 705116525035520.0000 - mae: 18809004.0000 - val_loss: 749479779106816.0000 - val_mae: 19690710.0000\n",
            "Epoch 51/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 706867193970688.0000 - mae: 18892330.0000 - val_loss: 749082830176256.0000 - val_mae: 19579898.0000\n",
            "Epoch 52/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 710695352008704.0000 - mae: 18920138.0000 - val_loss: 747790514782208.0000 - val_mae: 19581734.0000\n",
            "Epoch 53/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 721507462414336.0000 - mae: 18978448.0000 - val_loss: 747407524495360.0000 - val_mae: 19499372.0000\n",
            "Epoch 54/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 687971418243072.0000 - mae: 18641350.0000 - val_loss: 744882419269632.0000 - val_mae: 19535912.0000\n",
            "Epoch 55/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 706393338281984.0000 - mae: 18895490.0000 - val_loss: 744150529998848.0000 - val_mae: 19469300.0000\n",
            "Epoch 56/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 686657292468224.0000 - mae: 18567996.0000 - val_loss: 741760246480896.0000 - val_mae: 19540780.0000\n",
            "Epoch 57/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 689374127718400.0000 - mae: 18703166.0000 - val_loss: 741523821953024.0000 - val_mae: 19471194.0000\n",
            "Epoch 58/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 682257635344384.0000 - mae: 18486966.0000 - val_loss: 739789124927488.0000 - val_mae: 19490858.0000\n",
            "Epoch 59/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 683735036985344.0000 - mae: 18436050.0000 - val_loss: 738911743639552.0000 - val_mae: 19492756.0000\n",
            "Epoch 60/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 692893652090880.0000 - mae: 18662704.0000 - val_loss: 737644594069504.0000 - val_mae: 19485822.0000\n",
            "Epoch 61/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 691545233686528.0000 - mae: 18533332.0000 - val_loss: 736689433608192.0000 - val_mae: 19465590.0000\n",
            "Epoch 62/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 700405818327040.0000 - mae: 18738306.0000 - val_loss: 737231539011584.0000 - val_mae: 19394242.0000\n",
            "Epoch 63/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 678904608063488.0000 - mae: 18466496.0000 - val_loss: 734809177456640.0000 - val_mae: 19471572.0000\n",
            "Epoch 64/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 679074997469184.0000 - mae: 18415974.0000 - val_loss: 734192178561024.0000 - val_mae: 19421806.0000\n",
            "Epoch 65/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 687519574261760.0000 - mae: 18562316.0000 - val_loss: 734313041625088.0000 - val_mae: 19372652.0000\n",
            "Epoch 66/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 672878366294016.0000 - mae: 18199404.0000 - val_loss: 733267351306240.0000 - val_mae: 19334234.0000\n",
            "Epoch 67/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 697932722470912.0000 - mae: 18591518.0000 - val_loss: 732419632136192.0000 - val_mae: 19312868.0000\n",
            "Epoch 68/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 676555529388032.0000 - mae: 18271702.0000 - val_loss: 730326439559168.0000 - val_mae: 19348154.0000\n",
            "Epoch 69/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 683321310838784.0000 - mae: 18526586.0000 - val_loss: 730720771244032.0000 - val_mae: 19268956.0000\n",
            "Epoch 70/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 677209505267712.0000 - mae: 18365342.0000 - val_loss: 728683346132992.0000 - val_mae: 19357644.0000\n",
            "Epoch 71/200\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 672166811009024.0000 - mae: 18353646.0000 - val_loss: 727167155568640.0000 - val_mae: 19379560.0000\n",
            "Epoch 72/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 701725514137600.0000 - mae: 18660584.0000 - val_loss: 727784624226304.0000 - val_mae: 19233556.0000\n",
            "Epoch 73/200\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 685316390256640.0000 - mae: 18375094.0000 - val_loss: 726467478552576.0000 - val_mae: 19281344.0000\n",
            "Epoch 74/200\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 685814338027520.0000 - mae: 18435492.0000 - val_loss: 727696308961280.0000 - val_mae: 19239090.0000\n",
            "Epoch 75/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 674342950141952.0000 - mae: 18457704.0000 - val_loss: 724954442104832.0000 - val_mae: 19337822.0000\n",
            "Epoch 76/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 667193171771392.0000 - mae: 18304242.0000 - val_loss: 724481458831360.0000 - val_mae: 19358140.0000\n",
            "Epoch 77/200\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 693156920164352.0000 - mae: 18533406.0000 - val_loss: 724715064786944.0000 - val_mae: 19260050.0000\n",
            "Epoch 78/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 689619813269504.0000 - mae: 18428966.0000 - val_loss: 725306025443328.0000 - val_mae: 19201182.0000\n",
            "Epoch 79/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 671618665807872.0000 - mae: 18070120.0000 - val_loss: 724531522043904.0000 - val_mae: 19250244.0000\n",
            "Epoch 80/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 669779547389952.0000 - mae: 18297046.0000 - val_loss: 722818434072576.0000 - val_mae: 19293348.0000\n",
            "Epoch 81/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 677533573971968.0000 - mae: 18295672.0000 - val_loss: 724479915327488.0000 - val_mae: 19172602.0000\n",
            "Epoch 82/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 679011176939520.0000 - mae: 18197120.0000 - val_loss: 722865343168512.0000 - val_mae: 19223566.0000\n",
            "Epoch 83/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 679258003341312.0000 - mae: 18325192.0000 - val_loss: 722028428525568.0000 - val_mae: 19257634.0000\n",
            "Epoch 84/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 666295590715392.0000 - mae: 18115356.0000 - val_loss: 721440823312384.0000 - val_mae: 19237784.0000\n",
            "Epoch 85/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 672347132526592.0000 - mae: 18270570.0000 - val_loss: 721785561546752.0000 - val_mae: 19198688.0000\n",
            "Epoch 86/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 672675697524736.0000 - mae: 18109382.0000 - val_loss: 720005901582336.0000 - val_mae: 19257292.0000\n",
            "Epoch 87/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 682500636540928.0000 - mae: 18402918.0000 - val_loss: 720175754117120.0000 - val_mae: 19211806.0000\n",
            "Epoch 88/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 675382600663040.0000 - mae: 18226542.0000 - val_loss: 719188180074496.0000 - val_mae: 19237954.0000\n",
            "Epoch 89/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 672437595275264.0000 - mae: 18217254.0000 - val_loss: 719184824631296.0000 - val_mae: 19189690.0000\n",
            "Epoch 90/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 683516798959616.0000 - mae: 18484364.0000 - val_loss: 718800626384896.0000 - val_mae: 19193714.0000\n",
            "Epoch 91/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 669254420529152.0000 - mae: 18237692.0000 - val_loss: 718223959916544.0000 - val_mae: 19200954.0000\n",
            "Epoch 92/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 662015857131520.0000 - mae: 18250770.0000 - val_loss: 718111418351616.0000 - val_mae: 19232662.0000\n",
            "Epoch 93/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 675699690045440.0000 - mae: 18339210.0000 - val_loss: 718231409000448.0000 - val_mae: 19166872.0000\n",
            "Epoch 94/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 669141811855360.0000 - mae: 18091818.0000 - val_loss: 717955792896000.0000 - val_mae: 19154158.0000\n",
            "Epoch 95/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 675796595245056.0000 - mae: 18236510.0000 - val_loss: 717892643454976.0000 - val_mae: 19119510.0000\n",
            "Epoch 96/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 674320804216832.0000 - mae: 18286548.0000 - val_loss: 717531329331200.0000 - val_mae: 19158624.0000\n",
            "Epoch 97/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 683218768494592.0000 - mae: 18219500.0000 - val_loss: 716798903189504.0000 - val_mae: 19195312.0000\n",
            "Epoch 98/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 679839233212416.0000 - mae: 18200572.0000 - val_loss: 717684740194304.0000 - val_mae: 19140610.0000\n",
            "Epoch 99/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 679534760296448.0000 - mae: 18365084.0000 - val_loss: 717888415596544.0000 - val_mae: 19129764.0000\n",
            "Epoch 100/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 669829610602496.0000 - mae: 18092232.0000 - val_loss: 717240143970304.0000 - val_mae: 19145544.0000\n",
            "Epoch 101/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 675885447380992.0000 - mae: 18193512.0000 - val_loss: 717838218166272.0000 - val_mae: 19141822.0000\n",
            "Epoch 102/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 672128089194496.0000 - mae: 18180010.0000 - val_loss: 716619051433984.0000 - val_mae: 19197426.0000\n",
            "Epoch 103/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 674271881854976.0000 - mae: 18199286.0000 - val_loss: 716046075953152.0000 - val_mae: 19192884.0000\n",
            "Epoch 104/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 677121122893824.0000 - mae: 18339184.0000 - val_loss: 716767093587968.0000 - val_mae: 19109052.0000\n",
            "Epoch 105/200\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 667348864335872.0000 - mae: 18131804.0000 - val_loss: 714883012231168.0000 - val_mae: 19206422.0000\n",
            "Epoch 106/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 662050216869888.0000 - mae: 18013368.0000 - val_loss: 715316669710336.0000 - val_mae: 19190442.0000\n",
            "Epoch 107/200\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 681028939153408.0000 - mae: 18394220.0000 - val_loss: 716228477845504.0000 - val_mae: 19118066.0000\n",
            "Epoch 108/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 668907803246592.0000 - mae: 18284474.0000 - val_loss: 716059564834816.0000 - val_mae: 19114112.0000\n",
            "Epoch 109/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 656313885392896.0000 - mae: 18113554.0000 - val_loss: 716706829828096.0000 - val_mae: 19097740.0000\n",
            "Epoch 110/200\n",
            "85/85 [==============================] - 1s 7ms/step - loss: 668744594489344.0000 - mae: 18041404.0000 - val_loss: 714690141356032.0000 - val_mae: 19238538.0000\n",
            "Epoch 111/200\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 670914089844736.0000 - mae: 18127376.0000 - val_loss: 716320349880320.0000 - val_mae: 19083560.0000\n",
            "Epoch 112/200\n",
            "85/85 [==============================] - 0s 6ms/step - loss: 675416020877312.0000 - mae: 18208956.0000 - val_loss: 715687580401664.0000 - val_mae: 19142096.0000\n",
            "Epoch 113/200\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 647650466594816.0000 - mae: 17823462.0000 - val_loss: 715455987712000.0000 - val_mae: 19179058.0000\n",
            "Epoch 114/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 664788459847680.0000 - mae: 18114768.0000 - val_loss: 715930447380480.0000 - val_mae: 19122730.0000\n",
            "Epoch 115/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 659151986360320.0000 - mae: 17963520.0000 - val_loss: 715720061091840.0000 - val_mae: 19164276.0000\n",
            "Epoch 116/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 679682936668160.0000 - mae: 18395964.0000 - val_loss: 717839157690368.0000 - val_mae: 19049706.0000\n",
            "Epoch 117/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 666880914227200.0000 - mae: 18051756.0000 - val_loss: 715240098496512.0000 - val_mae: 19172274.0000\n",
            "Epoch 118/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 679649449345024.0000 - mae: 18234766.0000 - val_loss: 715296201506816.0000 - val_mae: 19200862.0000\n",
            "Epoch 119/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 669987249324032.0000 - mae: 18200214.0000 - val_loss: 715597318979584.0000 - val_mae: 19146700.0000\n",
            "Epoch 120/200\n",
            "85/85 [==============================] - 0s 4ms/step - loss: 679958955425792.0000 - mae: 18247280.0000 - val_loss: 715382302179328.0000 - val_mae: 19151680.0000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 714690141356032.0000 - mae: 19238538.0000\n",
            "Test Loss: 714690141356032.0\n",
            "Test MAE: 19238538.0\n",
            "22/22 [==============================] - 0s 2ms/step\n",
            "Custom Accuracy: 0.07669616490602493\n",
            "R^2: 0.42912859170787887\n"
          ]
        }
      ]
    }
  ]
}